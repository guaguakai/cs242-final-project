# -*- coding: utf-8 -*-
"""Final Project (CS242).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RdkLhYVtekDb95sM_pfAdA0puONt3l2U

# CS242: Final Project
Scalable Newton's Method

Kai Wang, Aditya Mate, Han Ching Ou

> Harvard CS 242: Computing at Scale (Spring 2020)
> 
> Instructor: Professor HT Kung
"""

## Code Cell 1.1

import sys
import time
import os
import math
import tqdm
import scipy
import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torch.autograd import Variable
!pip install ninja

"""**Loading the Train and Test Datasets**

For this assignment, we will use the CIFAR-10 dataset. It contains 10 object classes, where each sample is a color image (RGB channels) with a spatial resolution of 32 x 32 pixels. More details here: https://www.cs.toronto.edu/~kriz/cifar.html. *Code Cell 1.2* will take 1-2 minutes to execute as it downloads the train and test datasets.
"""

## Code Cell 1.2

# Load training data
transform_train = transforms.Compose([                                   
    transforms.RandomCrop(32, padding=4),                                       
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, 
                                        download=True,
                                        transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,
                                          shuffle=True, num_workers=2)

# Load testing data
transform_test = transforms.Compose([                                           
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True,
                                       transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False,
                                         num_workers=2)
print('Finished loading datasets!')

"""**Constructing our Convolutional Neural Network (CNN)**

For this assignment, we will use a 10-layer CNN which we call `ConvNet` that is provided in *Code Cell 1.3*. It has 9 convolutional layers (`nn.Conv2d`) followed by 1 fully connected (`nn.Linear`) layer. The Batch Normalization layers (`nn.BatchNorm2d`) help make the training process more stable and the ReLU layers (`nn.ReLU`) are the non-linear activation functions required for learning when stacking multiple convolutional layers together.

In this assignment, you will modify `ConvNet` to implement Shift-Convolution (Section 2) and Weight Pruning (Section 3).
"""

## Code Cell 1.3

def conv_block(in_channels, out_channels, kernel_size=3, stride=1,
               padding=1):
    '''
    A nn.Sequential layer executes its arguments in sequential order. In
    this case, it performs Conv2d -> BatchNorm2d -> ReLU. This is a typical
    block of layers used in Convolutional Neural Networks (CNNs). The 
    ConvNet implementation below stacks multiple instances of this three layer
    pattern in order to achieve over 90% classification accuracy on CIFAR-10.
    '''
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,
                  bias=False),
        nn.BatchNorm2d(out_channels),
        nn.ReLU(inplace=True)
        )

class ConvNet(nn.Module):
    '''
    A 9 layer CNN using the conv_block function above. Again, we use a
    nn.Sequential layer to build the entire model. The Conv2d layers get
    progressively larger (more filters) as the model gets deeper. This 
    corresponds to spatial resolution getting smaller (via the stride=2 blocks),
    going from 32x32 -> 16x16 -> 8x8. The nn.AdaptiveAvgPool2d layer at the end
    of the model reduces the spatial resolution from 8x8 to 1x1 using a simple
    average across all the pixels in each channel. This is then fed to the 
    single fully connected (linear) layer called classifier, which is the output
    prediction of the model.
    '''
    def __init__(self):
        super(ConvNet, self).__init__()
        self.model = nn.Sequential(
            conv_block(3, 32),
            conv_block(32, 32),
            conv_block(32, 64, stride=2),
            conv_block(64, 64),
            conv_block(64, 64),
            conv_block(64, 128, stride=2),
            conv_block(128, 128),
            conv_block(128, 256),
            conv_block(256, 256),
            nn.AdaptiveAvgPool2d(1)
            )

        self.classifier = nn.Linear(256, 10)

    def forward(self, x):
        '''
        The forward function is called automatically by the model when it is
        given an input image. It first applies the 8 convolution layers, then
        finally the single classifier layer.
        '''
        h = self.model(x)
        B, C, _, _ = h.shape
        h = h.view(B, C)
        return self.classifier(h)

"""**Training ConvNet on the CIFAR-10 Dataset**

Now that we have loaded our train and test datasets, and created our model, it is time to train the model. This training process will take around 15 seconds per epoch (an epoch is an entire pass through the training dataset). Usually, we need to train models for many epochs in order to achieve good classification accuracy. For this assignment, we will train most models for 100 epochs. This means that the training process takes roughly 15 seconds * 100 = 25 minutes. **Please do not close or refresh this colab instance during training and export results if you plan on using them in the future.** Note that the Google Colab is non-persistent, meaning that when the session is left idle for a period of time (such as 30-minutes) and the state of the machine will be lost. When this happens, you must execute all Code Cells in order up to your current point of progress. To avoid this, you may want to ensure that your session stays alive.

*Code Cell 1.4* provides a `train` function that will perform one epoch worth of training each time it is called. The `test` function will evaluate the performance of the model on the held out test set.
"""

## Code Cell 1.4

torch.manual_seed(43) # to give stable randomness

# tracks the highest accuracy observed so far
best_acc = 0

def moving_average(a, n=100):
    '''Helper function used for visualization'''
    ret = torch.cumsum(torch.Tensor(a), 0)
    ret[n:] = ret[n:] - ret[:-n]
    return ret[n - 1:] / n

def train(epoch, train_loss_tracker, train_acc_tracker):
    net.train()
    train_loss = 0
    correct = 0
    total = 0
    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        # update optimizer state
        optimizer.step()
        # compute average loss
        train_loss += loss.item()
        train_loss_tracker.append(loss.item())
        loss = train_loss / (batch_idx + 1)
        # compute accuracy
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
        acc = 100. * correct / total
        # Print status
        sys.stdout.write(f'\rEpoch {epoch}: Train Loss: {loss:.3f}' +  
                         f'| Train Acc: {acc:.3f}')
        sys.stdout.flush()
    train_acc_tracker.append(acc)
    sys.stdout.flush()

def test(epoch, test_loss_tracker, test_acc_tracker):
    global best_acc
    net.eval()
    test_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            loss = criterion(outputs, targets)

            test_loss += loss.item()
            test_loss_tracker.append(loss.item())
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

            loss = test_loss / (batch_idx + 1)
            acc = 100.* correct / total
    sys.stdout.write(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\n')
    sys.stdout.flush()
    
    # Save checkpoint.
    acc = 100.*correct/total
    test_acc_tracker.append(acc)
    if acc > best_acc:
        state = {
            'net': net.state_dict(),
            'acc': acc,
            'epoch': epoch,
        }
        if not os.path.isdir('checkpoint'):
            os.mkdir('checkpoint')
        torch.save(state, './checkpoint/ckpt.pth')
        best_acc = acc

device = 'cuda'
net = ConvNet()
net = net.to(device)
lr = 0.1 # 0.1, 1.0, 0.0001
milestones = [25,50,75,100]
epochs = 5 # 5 or 100

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,
                            weight_decay=5e-4)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,
                                                 milestones=milestones,
                                                 gamma=0.1)

# Records the training loss and training accuracy during training
train_loss_tracker, train_acc_tracker = [], []

# Records the test loss and test accuracy during training
test_loss_tracker, test_acc_tracker = [], []

print('Training for {} epochs, with learning rate {} and milestones {}'.format(
      epochs, lr, milestones))

start_time = time.time()
for epoch in range(0, epochs):
    train(epoch, train_loss_tracker, train_acc_tracker)
    test(epoch, test_loss_tracker, test_acc_tracker)
    scheduler.step()

total_time = time.time() - start_time
print('Total training time: {} seconds'.format(total_time))

import matplotlib.pyplot as plt

moving_average_train_loss = moving_average(train_loss_tracker)

plt.xlabel('batches')
plt.ylabel('training loss')
plt.plot(moving_average_train_loss)
plt.show()

plt.xlabel('epochs')
plt.ylabel('testing accuracy')
plt.plot(list(range(len(test_acc_tracker))), test_acc_tracker)
plt.show()

"""Newton method implementation."""

def newton_train(epoch, train_loss_tracker, train_acc_tracker):
    from scipy.sparse.linalg import LinearOperator
    net.train()
    train_loss = 0
    correct = 0
    total = 0
    regularization_const = 0.1

    for batch_idx, (inputs, targets) in enumerate(tqdm.tqdm(trainloader)):
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, targets)
        loss.backward(retain_graph=True)
        for parameter in net.parameters():
            parameter_size = parameter.nelement()
            grad = torch.autograd.grad(loss, parameter, create_graph=True)[0].flatten()
            def mv(v):
                z = grad @ torch.Tensor(v).to(device)
                return torch.autograd.grad(z, parameter, retain_graph=True)[0].cpu().detach().flatten().numpy() + regularization_const * v
            A = LinearOperator((parameter_size, parameter_size), matvec=mv)
            x, info = scipy.sparse.linalg.cg(A, parameter.grad.cpu().detach().flatten(), maxiter=100)
            parameter.grad = torch.Tensor(x.reshape(parameter.grad.shape)).to(device)

        # update optimizer state
        optimizer.step()
        # compute average loss
        train_loss += loss.item()
        train_loss_tracker.append(loss.item())
        loss = train_loss / (batch_idx + 1)
        # compute accuracy
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
        acc = 100. * correct / total
        # Print status
        sys.stdout.write(f'\rEpoch {epoch}: Train Loss: {loss:.3f}' +
                         f'| Train Acc: {acc:.3f}')
        # sys.stdout.flush()
    train_acc_tracker.append(acc)
    sys.stdout.flush()

device = 'cuda'
net = ConvNet()
net = net.to(device)
lr = 0.1 # 0.1, 1.0, 0.0001
milestones = [25,50,75,100]
epochs = 1 # 5 or 100

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,
                            weight_decay=5e-4)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,
                                                 milestones=milestones,
                                                 gamma=0.1)

# Records the training loss and training accuracy during training
train_loss_tracker, train_acc_tracker = [], []

# Records the test loss and test accuracy during training
test_loss_tracker, test_acc_tracker = [], []

print('Training for {} epochs, with learning rate {} and milestones {}'.format(
      epochs, lr, milestones))

start_time = time.time()
for epoch in range(0, epochs):
    newton_train(epoch, train_loss_tracker, train_acc_tracker)
    test(epoch, test_loss_tracker, test_acc_tracker)
    scheduler.step()

total_time = time.time() - start_time
print('Total training time: {} seconds'.format(total_time))

"""Block Newton's method implementation."""

def block_newton_train(epoch, train_loss_tracker, train_acc_tracker):
    from scipy.sparse.linalg import LinearOperator
    net.train()
    train_loss = 0
    correct = 0
    total = 0
    fixed_size = 16
    number_batches_recompute = 32
    regularization_const = 0.1
    minimum_parameter_size = 100
    with tqdm.tqdm(trainloader) as tqdm_loader:
        for batch_idx, (inputs, targets) in enumerate(tqdm_loader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = net(inputs)
            loss = criterion(outputs, targets)
            optimizer.zero_grad()
            loss.backward(create_graph=True, retain_graph=True)
            if batch_idx % number_batches_recompute == 0:
                A_list = [torch.zeros((fixed_size, fixed_size)).to(device) for parameter in net.parameters() if parameter.nelement() >= minimum_parameter_size]
                update_indices_list = [np.random.choice(parameter.nelement(), fixed_size) for parameter in net.parameters() if parameter.nelement() >= minimum_parameter_size]

                for i in range(fixed_size):
                    v = torch.zeros(fixed_size).to(device)
                    v[i] = 1
                
                    parameter_idx = 0
                    for parameter in net.parameters():
                        if parameter.nelement() < minimum_parameter_size:
                            continue
                        update_indices = update_indices_list[parameter_idx]
                        grad = parameter.grad.flatten()[update_indices]
                        grad_v = torch.autograd.grad(grad @ v, parameter, retain_graph=True)[0].flatten()[update_indices] + 0.01 * v
                        A_list[parameter_idx][:,i] = grad_v
                        parameter_idx += 1

            b_list = []
            parameter_idx = 0
            for parameter in net.parameters():
                if parameter.nelement() < minimum_parameter_size:
                    continue
                update_indices = update_indices_list[parameter_idx]
                b = parameter.grad.detach().flatten()[update_indices]
                b_list.append(b[:,None])
                parameter_idx += 1
                # x, LU = torch.solve(b[:,None], A)
                # x, info = scipy.sparse.linalg.cg(A.detach().numpy(), parameter.grad.detach().cpu().flatten()[update_indices], maxiter=100)
            A, b = torch.stack(A_list), torch.stack(b_list)
            x, LU = torch.solve(b, A)
            parameter_idx = 0
            for parameter in net.parameters():
                if parameter.nelement() < minimum_parameter_size:
                    continue
                update_indices = update_indices_list[parameter_idx]
                parameter.grad.flatten()[update_indices] = x[parameter_idx][:,0] # newton's update
                parameter_idx += 1

            # update optimizer state
            optimizer.step()
            # compute average loss
            train_loss += loss.item()
            train_loss_tracker.append(loss.item())
            average_loss = train_loss / (batch_idx + 1)
            # compute accuracy
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            acc = 100. * correct / total
            # Print status
            tqdm_loader.set_postfix(loss=f'{average_loss:.3f}', accuracy=f'{acc:.3f}')
            # sys.stdout.write(f'\rEpoch {epoch}: Train Loss: {loss:.3f}' +
            #                  f'| Train Acc: {acc:.3f}')
            # sys.stdout.flush()
        train_acc_tracker.append(acc)
        sys.stdout.flush()

device = 'cuda'
net = ConvNet()
net = net.to(device)
lr = 0.1 # 0.1, 1.0, 0.0001
milestones = [25,50,75,100]
epochs = 100 # 5 or 100

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,
                            weight_decay=5e-4)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,
                                                 milestones=milestones,
                                                 gamma=0.1)

# Records the training loss and training accuracy during training
train_loss_tracker, train_acc_tracker = [], []

# Records the test loss and test accuracy during training
test_loss_tracker, test_acc_tracker = [], []

print('Training for {} epochs, with learning rate {} and milestones {}'.format(
      epochs, lr, milestones))

start_time = time.time()
for epoch in range(0, epochs):
    block_newton_train(epoch, train_loss_tracker, train_acc_tracker)
    test(epoch, test_loss_tracker, test_acc_tracker)
    scheduler.step()

total_time = time.time() - start_time
print('Total training time: {} seconds'.format(total_time))